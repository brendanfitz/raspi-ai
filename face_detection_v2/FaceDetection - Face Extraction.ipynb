{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0eb20-f9d7-4183-8697-ba618269c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549e8506-a8ad-436a-8690-4179b14aea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils.extractors import Pathways\n",
    "from utils import extractors, transformers, modelers\n",
    "from utils.extractors import Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ff45a7-13ab-4b9e-961c-8006ccbc68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Pathways.img_path.glob('*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b8d7a2-d1ba-456f-93b4-fb7012ee155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fn = next(images)\n",
    "file_id = image_fn.stem\n",
    "label_fn = Pathways.labels_path / f'{file_id}.json'\n",
    "\n",
    "image = extractors.load_image(str(image_fn)).numpy()\n",
    "\n",
    "with open(label_fn, 'r', encoding = \"utf-8\") as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7d731-b48c-4a12-98c0-17cd098cc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = label['shapes']\n",
    "shape = shapes[0]\n",
    "points, name = shape['points'], shape['label']\n",
    "(x1, y1), (x2, y2) = [tuple(int(coord) for coord in point) for point in points]\n",
    "\n",
    "face = image[y1:y2, x1:x2]\n",
    "face_resized = cv2.resize(face, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6d950-2947-4557-9a95-f63021298e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,10), ncols=2)\n",
    "\n",
    "cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.imshow(image)\n",
    "title = f'Coords: ({x1}, {y1}), ({x2}, {y2})'\n",
    "ax.set_title(title)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.imshow(face_resized)\n",
    "ax.set_title(name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d817036-52c7-49b9-bb60-cc57e1a4f9fd",
   "metadata": {},
   "source": [
    "# Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33eb18-2ce8-466c-9407-409b04b667ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = transformers.create_ds('val')\n",
    "val_iter = val.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0e154-718f-4fc0-89e7-5cbf63b839af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, (y_classes, y_coords) = next(val_iter)\n",
    "X.shape, y_coords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b2354-2747-410f-9cea-14d8434f3fd7",
   "metadata": {},
   "source": [
    "## Coord Swap Details\n",
    "\n",
    "> Current Coords\n",
    ">> [x1, y1, x2, y2]\n",
    "\n",
    "> `crop_and_resize` Coords\n",
    ">>  [y1, x1, y2, x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d4023-73f4-4e9d-82cf-5bd5d796cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i+4 for i in col_swap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c30ea0-0248-4928-a74e-52b36a006130",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_swap = [1, 0, 3, 2]\n",
    "y_coords_brendan, y_coords_kara = y_coords[:, [1, 0, 3, 2]], y_coords[:, [i+4 for i in col_swap]]\n",
    "X_cropped_brendan = tf.image.crop_and_resize(X, y_coords_brendan, np.array(range(X.shape[0])),  crop_size=(120, 120))\n",
    "X_cropped_kara = tf.image.crop_and_resize(X, y_coords_kara, np.array(range(X.shape[0])),  crop_size=(120, 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37c0fc-abd4-472b-b64d-be579ea7d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "image, face_resized_brendan, face_resized_kara = X[i], X_cropped_brendan[i].numpy(), X_cropped_kara[i].numpy()\n",
    "coords_brendan, coords_kara = y_coords_brendan[i], y_coords_kara[i]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,10), ncols=3)\n",
    "\n",
    "# cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.imshow(image)\n",
    "# title = f'Coords: ({x1}, {y1}), ({x2}, {y2})'\n",
    "# ax.set_title(title)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.imshow(face_resized_brendan)\n",
    "# ax.set_title(name)\n",
    "\n",
    "ax = axes[2]\n",
    "ax.imshow(face_resized_kara)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection",
   "language": "python",
   "name": "face_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
