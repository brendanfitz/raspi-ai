{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab4a5c-5de0-4d90-a295-388f3b9268f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import albumentations as alb\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcad162-8a3a-4b9e-a9b2-cf867c417cc1",
   "metadata": {},
   "source": [
    "### 2.2 Limit GPU Memory Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd661dc2-1a0f-4601-9708-79d6d3ef1301",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321986f9-f98e-4cbf-bb52-f606f6710782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2005e86c-d741-460b-9f01-3010c9a698d9",
   "metadata": {},
   "source": [
    "### 2.3 Load Image into TF Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6cd04a-444c-4971-ba1b-a8b00d8d3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wd = Path('/data') / 'raspi_face_detection'\n",
    "img_path = data_wd / 'images'\n",
    "labels_path = data_wd / 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7c50f-a1e8-43c5-8e93-42d1f1e7a59d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = tf.data.Dataset.list_files(f'{img_path}/*.jpg', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532c8ed-1537-4aeb-b225-e0e83f7291d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973c554-ff8b-483c-b7f9-ff24bbf1f32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(x): \n",
    "    byte_img = tf.io.read_file(x)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429289c0-aef0-4973-a4b9-cda1f08adb39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = images.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15723d09-750c-41fc-8152-c230b350fcba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b1e41-59e8-4de4-9cde-be38b84f6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920cec1-205d-4ad2-90a9-b9307161bb6b",
   "metadata": {},
   "source": [
    "### 2.4 View Raw Images with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0090aa2-47fc-48c6-8839-fa0f057d36a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_generator = images.batch(4).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448e366-ef95-4a1b-a057-3b433e14e166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_images = image_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca22f51-1941-402e-8018-49139a4fec6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, image in enumerate(plot_images):\n",
    "    ax[idx].imshow(image) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267faaa0-31e3-450b-a545-e656d1fdc80a",
   "metadata": {},
   "source": [
    "# 3. Partition Unaugmented Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2e4347-44a8-4e05-89b5-78465fcf5b21",
   "metadata": {},
   "source": [
    "### 3.1 MANUALLY SPLT DATA INTO TRAIN TEST AND VAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d322b6-1582-49cf-a619-ce1c176486b5",
   "metadata": {},
   "source": [
    "#### 3.1.1 Find Errors Where x/y-Max < x/y-min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b4ad5-5fe4-49b8-88a9-f1de0f9e6b20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "errors = list()\n",
    "\n",
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                         bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                    label_fields=['class_labels']))\n",
    "\n",
    "EMPTY_PHOTOS = ['de1c5f22-0cbd-11ef-9a53-dca632a68397', 'dce7e950-0cbd-11ef-9a53-dca632a68397', '22814110-0d58-11ef-abd8-dca632a68397', 'dbb39962-0cbd-11ef-9a53-dca632a68397']\n",
    "\n",
    "fns = list(img_path.glob('*'))\n",
    "for fn in fns:\n",
    "    stem = fn.stem\n",
    "\n",
    "    if stem in EMPTY_PHOTOS:\n",
    "        continue\n",
    "    \n",
    "    img_fn   = img_path / f'{stem}.jpg'\n",
    "    label_fn = labels_path / f'{stem}.json'\n",
    "    \n",
    "    \n",
    "    img = cv2.imread(str(img_fn))\n",
    "    with open(label_fn, 'r') as f:\n",
    "        label = json.load(f)\n",
    "    \n",
    "    shapes = label['shapes']\n",
    "    for shape in shapes:\n",
    "        coords = [0,0,0,0]\n",
    "        points = shape['points']\n",
    "        coords[0] = points[0][0]\n",
    "        coords[1] = points[0][1]\n",
    "        coords[2] = points[1][0]\n",
    "        coords[3] = points[1][1]\n",
    "        coords = list(np.divide(coords, [640,480,640,480]))\n",
    "    \n",
    "        try:\n",
    "            augmented = augmentor(image=img, bboxes=[coords], class_labels=['face'])\n",
    "        except ValueError:\n",
    "            errors.append([stem, shape['label']])\n",
    "\n",
    "print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2cec2c-12b2-4034-b664-6eaad2996f69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame(errors).to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144b7fa-06e3-45d9-8961-dff5844be30d",
   "metadata": {},
   "source": [
    "### 3.1.1 Programmatically Split Data into Train/Test/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4405a37-3dd9-444d-b9a9-6251b7fa72d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = list()\n",
    "for label_fn in labels_path.glob('*'):\n",
    "    with open(label_fn, 'r') as f:\n",
    "        label_json = json.load(f)\n",
    "    labels.append(dict(\n",
    "        image_path=Path(label_json['imagePath']).name,\n",
    "        labels=', '.join(sorted([x['label'] for x in label_json['shapes']]))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5d7aa-10af-4300-87eb-9edfa938ac3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame(labels)\n",
    "df_labels.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a477a-4d34-47ab-8106-da0116e29441",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_labels, test_size=0.3, random_state=42, stratify=df_labels.labels)\n",
    "test, val = train_test_split(test, test_size=0.5, random_state=42, stratify=test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b741b6f-80bb-4788-9f36-5d76a2d6668e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Training Set')\n",
    "print(train.labels.value_counts().to_string(header=False))\n",
    "print('\\nTest Set')\n",
    "print(test.labels.value_counts().to_string(header=False))\n",
    "print('\\nValidation Set')\n",
    "print(val.labels.value_counts().to_string(header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be555b-83ff-46f6-afa1-59cb8f302113",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_sets_files = dict(\n",
    "    train=train.image_path.tolist(),\n",
    "    test=test.image_path.tolist(),\n",
    "    val=val.image_path.tolist(),\n",
    ")\n",
    "print('Model Set Percentages Check')\n",
    "print({k: len(v) for k, v in model_sets_files.items()})\n",
    "print({k: len(v) / len(df_labels) for k, v in model_sets_files.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e4538-f775-49fb-8aec-e961aa5b384c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.2 Moving Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e389a2-e5ed-4294-a500-60df7fff10ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_sets_path = data_wd / 'model_sets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1950a3e-c603-43a1-8dcc-d5ecf2e597e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(model_sets_path.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12271b30-6faa-4800-9438-68bdd515bba2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = 'train'\n",
    "model_set_filepath = model_sets_path / folder\n",
    "model_set_filepath_images = model_set_filepath / 'images'\n",
    "model_set_filepath_labels = model_set_filepath / 'labels'\n",
    "for p in [model_set_filepath, model_set_filepath_images, model_set_filepath_labels]:\n",
    "    p.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9bb7b-26e0-438b-ba4c-fbd67bda5b78",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in ['train','test','val']:\n",
    "    model_set_filepath = model_sets_path / folder\n",
    "    model_set_filepath_images = model_set_filepath / 'images'\n",
    "    model_set_filepath_labels = model_set_filepath / 'labels'\n",
    "    for p in [model_set_filepath, model_set_filepath_images, model_set_filepath_labels]:\n",
    "        p.mkdir(exist_ok=True)\n",
    "\n",
    "    for img_filename in model_sets_files[folder]:\n",
    "        src_img_filepath, dst_img_filepath = [p / img_filename for p in [img_path, model_set_filepath_images]]\n",
    "        shutil.copyfile(src_img_filepath, dst_img_filepath)\n",
    "        \n",
    "        label_filename = img_filename.split('.')[0]+'.json'\n",
    "        src_label_filepath, dst_label_filepath = [p / label_filename for p in [labels_path, model_set_filepath_labels]]\n",
    "        shutil.copyfile(src_label_filepath, dst_label_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection",
   "language": "python",
   "name": "face_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
