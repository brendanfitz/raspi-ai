{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cfb53-49e5-442b-9122-b7607ce692c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data_wd = Path('/data') / 'raspi_face_detection'\n",
    "img_path = data_wd / 'images'\n",
    "labels_path = data_wd / 'labels'\n",
    "\n",
    "model_sets_path = data_wd / 'model_sets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6dee7-5808-4bd8-8838-d67699ac07fc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.1 Setup Albumentations Transform Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74846c-6b46-494c-8cd8-ca6eda310223",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                         bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                    label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace05538-5e23-4299-bbf4-b31e754eab62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.2 Load a Test Image and Annotation with OpenCV and JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ddead-916a-4229-8431-22e06b15e8e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = 'train'\n",
    "model_set_filepath = model_sets_path / folder\n",
    "model_set_filepath_images = model_set_filepath / 'images'\n",
    "model_set_filepath_labels = model_set_filepath / 'labels'\n",
    "fns = list(model_set_filepath_images.glob('*'))\n",
    "# fn = fns[1].stem\n",
    "fn = '49e246c6-0968-11ef-b027-dca632a68397'\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e99c0-f4fd-4a6c-8ca8-320883cc0cf6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_sets_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a8f71-37ea-4681-bbdd-9195e9a603d2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_fn   = model_set_filepath_images / f'{fn}.jpg'\n",
    "label_fn = model_set_filepath_labels / f'{fn}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf2c97-2f2a-41eb-aebc-7c093d522498",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(str(img_fn))\n",
    "print(('height', 'width', 'layers'))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a589a7b-9163-47e5-838f-cf9fba1e84db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(label_fn, 'r') as f:\n",
    "    label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34413892-ea5e-4bc8-baec-515fb472ee24",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8ec0f9-0c84-47f4-89ac-5b7d08dfb512",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.3 Extract Coordinates and Rescale to Match Image Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a98ea8-c79b-4183-b141-8a5dfa66f99f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shapes, coords, labels = label['shapes'], list(), list()\n",
    "for shape in shapes:\n",
    "    c = [0,0,0.00001,0.00001]\n",
    "    c[0] = shape['points'][0][0]\n",
    "    c[1] = shape['points'][0][1]\n",
    "    c[2] = shape['points'][1][0]\n",
    "    c[3] = shape['points'][1][1]\n",
    "    c = list(np.divide(c, [640,480,640,480]))\n",
    "\n",
    "    labels.append(shape['label'])\n",
    "    coords.append(c)\n",
    "coords, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd9f49-17c8-4b5b-aed3-81f95f5c1cb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.4 Apply Augmentations and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc97fcc-af98-49e5-9288-b6ca8108c760",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img, bboxes=coords, class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de4b44-5b41-4a83-bf7b-de471f4ad1a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for bbox in augmented['bboxes']:\n",
    "    cv2.rectangle(augmented['image'], \n",
    "                  tuple(np.multiply(bbox[:2], [450,450]).astype(int)),\n",
    "                  tuple(np.multiply(bbox[2:], [450,450]).astype(int)), \n",
    "                        (255,0,0), 2)\n",
    "\n",
    "plt.imshow(augmented['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1d75a-f37d-412b-8f7e-c9082756b13f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 5. Build and Run Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b33e2-1026-401e-9f49-a0526bd6f44c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_sets_path = data_wd / 'aug_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834ffdb-bc32-43ed-b862-d9af68b3bf34",
   "metadata": {},
   "source": [
    "### 5.1 Run Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d171862-a720-44c4-ae79-392815d8c85f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_nums = dict(brendan=1, kara=2)\n",
    "\n",
    "for partition in ['train','test','val']: \n",
    "    model_set_filepath = model_sets_path / partition\n",
    "    model_set_filepath_images = model_set_filepath / 'images'\n",
    "    model_set_filepath_labels = model_set_filepath / 'labels'\n",
    "\n",
    "    aug_set_filepath = aug_sets_path / partition\n",
    "    aug_set_filepath_images = aug_set_filepath / 'images'\n",
    "    aug_set_filepath_labels = aug_set_filepath / 'labels'\n",
    "    \n",
    "    for image in list(model_set_filepath_images.glob('*')):\n",
    "        img_path = model_set_filepath_images / image\n",
    "        img = cv2.imread(str(img_path))\n",
    "\n",
    "        label_path = model_set_filepath_labels / f'{img_path.stem}.json'\n",
    "        if label_path.is_file():\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "        shapes, coords, labels = label['shapes'], list(), list()\n",
    "        shapes.sort(key=lambda x: x['label'])\n",
    "        for shape in shapes:\n",
    "            c = [0,0,0.00001,0.00001]\n",
    "            c[0] = shape['points'][0][0]\n",
    "            c[1] = shape['points'][0][1]\n",
    "            c[2] = shape['points'][1][0]\n",
    "            c[3] = shape['points'][1][1]\n",
    "            c = list(np.divide(c, [640,480,640,480]))\n",
    "        \n",
    "            labels.append(shape['label'])\n",
    "            coords.append(c)\n",
    "\n",
    "\n",
    "        for x in range(60):\n",
    "            augmented = augmentor(image=img, bboxes=coords, class_labels=labels)\n",
    "            aug_image, aug_labels, aug_bboxes = augmented['image'], augmented['class_labels'], augmented['bboxes']\n",
    "            \n",
    "            cv2.imwrite(str(aug_set_filepath_images / f'{img_path.stem}_{x}.jpg'), aug_image)\n",
    "\n",
    "            annotation = {}\n",
    "            annotation['image'] = str(image)\n",
    "\n",
    "            if not label_path.is_file() or len(aug_labels) == 0: \n",
    "                annotation['bboxes'] = [[0,0,0,0], [0,0,0,0]]\n",
    "                annotation['classes'] = [0] \n",
    "            else:\n",
    "                if len(aug_labels) == 1:\n",
    "                    if aug_labels[0] == 'kara':\n",
    "                        aug_bboxes.insert(0, (0, 0, 0, 0))\n",
    "                    else:\n",
    "                        aug_bboxes.append((0, 0, 0, 0))\n",
    "                        \n",
    "                assert len(aug_bboxes) == 2\n",
    "                assert len(aug_bboxes[0]) == 4\n",
    "                assert len(aug_bboxes[1]) == 4\n",
    "                \n",
    "                annotation['bboxes'] = aug_bboxes\n",
    "                annotation['classes'] = list(map(lambda x: class_nums[x], aug_labels))\n",
    "                # Add new code here\n",
    "                    \n",
    "\n",
    "\n",
    "            with open(str(aug_set_filepath_labels / f'{img_path.stem}_{x}.json'), 'w') as f:\n",
    "                json.dump(annotation, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf275bdc-95dd-4c78-8fdc-5b242e309098",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    aug_set_filepath = aug_sets_path / partition\n",
    "    aug_set_filepath_images = aug_set_filepath / 'images'\n",
    "    aug_set_filepath_labels = aug_set_filepath / 'labels'\n",
    "\n",
    "    cnt_images, cnt_labels = len(list(aug_set_filepath_images.glob('*'))), len(list(aug_set_filepath_labels.glob('*')))\n",
    "\n",
    "    print(f'{partition} augmentation set' + '\\n' + '-'*10)\n",
    "    print(f'{cnt_images} Images & {cnt_labels} Labels\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection",
   "language": "python",
   "name": "face_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
